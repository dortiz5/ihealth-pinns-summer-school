{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCgpgtSqTbvP"
   },
   "source": [
    "# Redes Neuronales Artificiales (ANN) vs. Redes Neuronales Informadas por la Física\n",
    "\n",
    "By Tabita Catalán, Tomás Banduc, David Ortiz y Francisco Sahli, 2025\n",
    "\n",
    "Accede al trabajo fundacional de las PINNs [aquí](https://www.sciencedirect.com/science/article/pii/S0021999118307125).\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Las Redes Neuronales Artificiales (ANNs) son herramientas potentes para resolver tareas complejas basadas en datos. Sin embargo, suelen necesitar grandes volúmenes de datos y pueden carecer de interpretabilidad al aplicarse a sistemas físicos. Las Redes Neuronales Informadas por la Física (PINNs) enfrentan este desafío integrando leyes físicas conocidas directamente en el proceso de entrenamiento, lo que las hace especialmente útiles cuando se dispone de ecuaciones gobernantes pero los datos son limitados. En esta actividad, exploraremos ambos enfoques aplicándolos al modelado del **péndulo oscilante**, un sistema clásico no lineal.  \n",
    "\n",
    "### Resumen de la Actividad\n",
    "\n",
    "En esta actividad, programaremos una Red Neuronal Artificial (ANN) y una Red Neuronal Informada por la Física (PINN) para resolver el modelo matemático no lineal de un **péndulo oscilante**. Este enfoque resaltará los beneficios de integrar las leyes físicas en la función de pérdida de la red.\n",
    "\n",
    "### Objetivos de la Actividad\n",
    "\n",
    "Al finalizar esta actividad, podrás:\n",
    "\n",
    "- Comprender la necesidad de soluciones numéricas en modelos complejos.  \n",
    "- Reconocer las ventajas de las Redes Neuronales Informadas por la Física (PINNs) sobre las Redes Neuronales Artificiales (ANNs) tradicionales.  \n",
    "- Utilizar PyTorch para entrenar PINNs, integrando datos con la física del modelo.\n",
    "- Aplicar PINNs para resolver modelos no lineales.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7OpUDIRTbvR"
   },
   "source": [
    "## Modelo matemático para describir un péndulo oscilante\n",
    "\n",
    "Queremos resolver el problema matemático relacionado con el **péndulo oscilante** [(wiki)](https://en.wikipedia.org/wiki/Pendulum_(mechanics)):\n",
    "\n",
    "| ![GIF](https://github.com/dortiz5/deep-learning-UV-PINN-curso/blob/main/data/figures/Oscillating_pendulum.gif?raw=1) | <img src=\"https://github.com/dortiz5/deep-learning-UV-PINN-curso/blob/main/data/figures/Pendulum_gravity.svg?raw=1\" alt=\"Diagrama del proyecto\" width=\"300\"/> |\n",
    "|-------------------------------------------|-------------------------------------------|\n",
    "| Vectores de velocidad y aceleración del péndulo  | Diagrama de fuerzas |\n",
    "\n",
    "\n",
    "**Supuestos:**\n",
    "\n",
    "- La varilla es rígida y sin masa [(Tarea - el caso de una cuerda elástica)](https://en.wikipedia.org/wiki/Elastic_pendulum#:~:text=In%20physics%20and%20mathematics%2C%20in,%2Ddimensional%20spring%2Dmass%20system.).\n",
    "- El peso es una masa puntual.  \n",
    "- Dos dimensiones [(Tarea - una dimensión adicional de movimiento)](https://www.instagram.com/reel/CffUr64PjCx/?igsh=MWlmM2FscG9oYnp6bw%3D%3D).\n",
    "- No hay resistencia del aire [(Tarea - inmersión en un fluido)](https://www.youtube.com/watch?v=erveOJD_qv4&ab_channel=Lettherebemath).\n",
    "- El campo gravitacional es uniforme y el soporte no se mueve.\n",
    "\n",
    "Nos interesa encontrar el ángulo vertical $\\theta(t) \\in [0, 2\\pi)$ tal que:\n",
    "\n",
    "$$\n",
    "\\frac{d^2\\theta}{dt^2}+\\frac{g}{l}\\sin\\theta=0,\\quad\\theta(0)=\\theta_0,\\quad\\theta'(0)=0,\\quad t\\in\\mathbb{R},\n",
    "$$\n",
    "\n",
    "donde $g\\approx 9.81[m/s^2]$, $l$ es el largo de la varilla y $t$ la variable temporal.  \n",
    "\n",
    "**Repaso de conceptos de ecuaciones diferenciales:**\n",
    "\n",
    "- ¿Por qué esta es una ecuación diferencial no lineal? ¿Qué supuestos deberían hacerse para linealizar el modelo?\n",
    "- ¿Es una ecuación diferencial ordinaria (EDO) o una ecuación diferencial parcial (EDP)?  \n",
    "- ¿Cuál es el orden? ¿cuál es el grado?  \n",
    "\n",
    "Un método útil es convertir el modelo en un sistema acoplado de EDOs:  \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d\\theta}{dt} &= \\omega, \\quad \\text{(velocidad angular)}\\\\\n",
    "\\frac{d\\omega}{dt} & = -\\frac{g}{l}\\sin\\theta, \\quad \\text{(aceleración angular)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Flujo de Trabajo  \n",
    "1. Calcular la solución numérica del modelo no lineal del péndulo oscilante.  \n",
    "2. Preparar los datos de entrenamiento añadiendo ruido, remuestreando y limitando el tiempo para simular un escenario real.  \n",
    "3. Definir el modelo ANN utilizando la arquitectura de PyTorch y entrenar con los datos preparados. Graficar la solución.  \n",
    "4. Definir el modelo PINN utilizando la arquitectura de PyTorch y entrenar con los datos preparados. Graficar la solución.  \n",
    "5. Comparar las soluciones obtenidas con ambas arquitecturas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gKS9hYYTbvS"
   },
   "source": [
    "## Configuración Inicial  \n",
    "\n",
    "Comenzamos importando algunos paquetes útiles y definiendo algunas funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvjIWMEtTbvS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLwL3oIbTbvS",
    "outputId": "d732db5c-47d7-4528-8888-d66be1381707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy for numerical operations\n",
    "import numpy as np\n",
    "# Import PyTorch for building and training neural networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Import Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "# Import the time module to time our training process\n",
    "import time\n",
    "# Ignore Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Actualización de los parámetros de Matplotlib\n",
    "gray = '#5c5c5c' #'#5c5c5c' '000'\n",
    "mlp.rcParams.update(\n",
    "    {\n",
    "        \"image.cmap\" : 'viridis', # plasma, inferno, magma, cividis\n",
    "        \"text.color\" : gray,\n",
    "        \"xtick.color\" :gray,\n",
    "        \"ytick.color\" :gray,\n",
    "        \"axes.labelcolor\" : gray,\n",
    "        \"axes.edgecolor\" :gray,\n",
    "        \"axes.spines.right\" : False,\n",
    "        \"axes.spines.top\" : False,\n",
    "        \"axes.formatter.use_mathtext\": True,\n",
    "        \"axes.unicode_minus\": False,\n",
    "\n",
    "        'font.size' : 15,\n",
    "        'interactive': False,\n",
    "        \"font.family\": 'sans-serif',\n",
    "        \"legend.loc\" : 'best',\n",
    "        'text.usetex': False,\n",
    "        'mathtext.fontset': 'stix',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Util function to calculate the signal-to-noise ratio\n",
    "def calculate_snr(signal, noise):\n",
    "    # Ensure numpy arrays\n",
    "    signal, noise = np.array(signal), np.array(noise)\n",
    "\n",
    "    # Calculate the power of the signal and the noise\n",
    "    signal_power = np.mean(signal**2)\n",
    "    noise_power = np.mean(noise**2)\n",
    "\n",
    "    # Calculate the SNR in decibels (dB)\n",
    "    snr = 10 * np.log10(signal_power / noise_power)\n",
    "    return snr\n",
    "\n",
    "# Util function to calculate the relative l2 error\n",
    "def relative_l2_error(u_num, u_ref):\n",
    "    # Calculate the L2 norm of the difference\n",
    "    l2_diff = torch.norm(u_num - u_ref, p=2)\n",
    "\n",
    "    # Calculate the L2 norm of the reference\n",
    "    l2_ref = torch.norm(u_ref, p=2)\n",
    "\n",
    "    # Calculate L2 relative error\n",
    "    relative_l2 = l2_diff / l2_ref\n",
    "    return relative_l2\n",
    "\n",
    "# Util function to plot the solutions\n",
    "def plot_comparison(time, theta_true, theta_pred, loss):\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    t_np = time.detach().cpu().data.numpy()\n",
    "    theta_pred_np = theta_pred.detach().cpu().data.numpy()\n",
    "\n",
    "    # Create a figure with 2 subplots\n",
    "    _, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot the true and predicted values\n",
    "    axs[0].plot(t_np, theta_true, label = r'$\\theta(t)$ (numerical solution)')\n",
    "    axs[0].plot(t_np, theta_pred_np, label = r'$\\theta_{pred}(t)$ (predicted solution) ')\n",
    "    axs[0].set_title('Angular displacement Numerical Vs. Predicted')\n",
    "    axs[0].set_xlabel(r'Time $(s)$')\n",
    "    axs[0].set_ylabel('Amplitude')\n",
    "    axs[0].set_ylim(-1,1.3)\n",
    "    axs[0].legend(loc='best', frameon=False)\n",
    "\n",
    "\n",
    "    # Plot the difference between the predicted and true values\n",
    "    difference = np.abs(theta_true.reshape(-1,1) - theta_pred_np.reshape(-1,1))\n",
    "    axs[1].plot(t_np, difference)\n",
    "    axs[1].set_title('Absolute Difference')\n",
    "    axs[1].set_xlabel(r'Time $(s)$')\n",
    "    axs[1].set_ylabel(r'$|\\theta(t) - \\theta_{pred}(t)|$')\n",
    "    # Display the plot\n",
    "    plt.legend(loc='best', frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the loss values recorded during training\n",
    "    # Create a figure with 1 subplots\n",
    "    _, axs = plt.subplots(1, 1, figsize=(6, 3))\n",
    "    axs.plot(loss)\n",
    "    axs.set_xlabel('Iteration')\n",
    "    axs.set_ylabel('Loss')\n",
    "    axs.set_yscale('log')\n",
    "    axs.set_xscale('log')\n",
    "    axs.set_title('Training Progress')\n",
    "    axs.grid(True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Util function to calculate tensor gradients with autodiff\n",
    "def grad(outputs, inputs):\n",
    "    \"\"\"Computes the partial derivative of an output with respect\n",
    "    to an input.\n",
    "    Args:\n",
    "        outputs: (N, 1) tensor\n",
    "        inputs: (N, D) tensor\n",
    "    \"\"\"\n",
    "    return torch.autograd.grad(outputs, inputs,\n",
    "                        grad_outputs=torch.ones_like(outputs),\n",
    "                        create_graph=True,\n",
    "                        )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtSeOyujTbvT"
   },
   "source": [
    "## 1. Solución numérica del péndulo oscilante  \n",
    "Para la solución numérica utilizamos el método [Runge-Kutta de cuarto orden](https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods) de `scipy`. Comenzamos definiendo los parámetros para este ejemplo, el modelo del péndulo y el dominio:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77rbOuBRTbvT"
   },
   "outputs": [],
   "source": [
    "g = 9.81  # gravity acceleration (m/s^2)\n",
    "L = 1.0   # Pendulum's rod length (m)\n",
    "theta0 = np.pi / 4  # Initial condition (Position in rads)\n",
    "omega0 = 0.0        # Initial angular speed (rad/s)\n",
    "sample_freq = 100   # sample rate 100Hz\n",
    "\n",
    "# Simulation time\n",
    "t_span = (0, 10)  # from 0 to 10 seconds\n",
    "t_eval = np.linspace(t_span[0], t_span[1], sample_freq*t_span[1])  # Points to be evaluated\n",
    "\n",
    "# We define the system of coupled ODEs\n",
    "def pendulum(t, y):\n",
    "    theta, omega = y\n",
    "    dtheta_dt = omega\n",
    "    domega_dt = -(g / L) * np.sin(theta)\n",
    "    return [dtheta_dt, domega_dt]\n",
    "\n",
    "# Initial conditions\n",
    "y0 = [theta0, omega0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csYieohwTbvU"
   },
   "source": [
    "Ahora resolvemos el problema numéricamente utilizando `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "5-DGSnPhTbvU",
    "outputId": "00acced0-2907-4e90-c1c0-73fc56d3c60d"
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Solve the initial value problem using Runge-Kutta 4th order\n",
    "num_sol = solve_ivp(pendulum, t_span, y0, t_eval=t_eval, method='RK45')\n",
    "\n",
    "# We extract the solutions\n",
    "theta_num = num_sol.y[0]\n",
    "omega_num = num_sol.y[1]\n",
    "\n",
    "# We graph the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_eval, theta_num, label=r'Angular Displacement $\\theta(t)[rad]$')\n",
    "plt.plot(t_eval, omega_num, label=r'Angular Velocity $\\omega(t)[rad/s]$')\n",
    "plt.xlabel(r'Time $[s]$')\n",
    "plt.ylim(-2.5,3.3)\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.title('Nonlinear Pendulum Solution')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaZRsQHvTbvU"
   },
   "source": [
    "## 2. Preparación de los datos de entrenamiento  <a id='data_prep'></a>\n",
    "\n",
    "A continuación, consideramos la solución numérica como los **datos de entrenamiento** que provienen de las mediciones de un sensor. Añadimos ruido gaussiano, remuestreamos y recortamos los datos a $2.5$ s para evaluar el rendimiento de la ANN, simulando un escenario real. Además, calculamos la relación señal-ruido $SNR = 10\\log_{10} \\left(\\frac{P_{signal}}{P_{noise}}\\right)$, donde $P_{signal}$ y $P_{noise}$ son la potencia de la señal y del ruido, respectivamente, para determinar el nivel de distorsión en la señal. Finalmente, llamamos a los datos de entrenamiento con ruido $\\theta_{data}(t)$.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "agIihTIyTbvV",
    "outputId": "fd129006-9880-4b5c-cb8d-7ec2df27ca63"
   },
   "outputs": [],
   "source": [
    "# Add gaussian noise\n",
    "std_deviation = 0.05\n",
    "noise = np.random.normal(0,std_deviation,theta_num.shape[0])\n",
    "theta_noisy = theta_num + noise\n",
    "print(f'SNR: {calculate_snr(theta_noisy, noise):.4f} dB')\n",
    "\n",
    "# Resample and cut to 2.5s\n",
    "resample = 5          # resample\n",
    "cut_time = int(2.5*sample_freq)  # 2.5s times 100Hz\n",
    "\n",
    "theta_data = theta_noisy[:cut_time:resample]\n",
    "t_data = t_eval[:cut_time:resample]\n",
    "\n",
    "# We graph the observed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_eval, theta_num, label=r'Angular Displacement (model) $\\theta(t)$ ')\n",
    "plt.plot(t_data, theta_data, label=r'Training data (measures) $\\theta_{data}(t)$ ')\n",
    "plt.xlabel(r'Time $[s]$')\n",
    "plt.ylabel(r'Angular displacement $[rad]$')\n",
    "plt.ylim(-1,1.3)\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.title('Training data')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PpIuan2TbvV"
   },
   "source": [
    "## 3. Entrenando la Red Neuronal Artificial\n",
    "\n",
    "Entrenaremos la red neuronal artificial para aproximar directamente la solución de la ecuación diferencial, es decir,\n",
    "\n",
    "$$\n",
    "\\theta_{NN}(t; \\Theta) \\approx \\theta(t)\n",
    "$$\n",
    "\n",
    "donde $\\Theta$ son los parámetros entrenables de la ANN. Utilizaremos `PyTorch` para definir la red y la entrenaremos con el optimizador ADAM. Además, convertiremos el dominio temporal y las observaciones a `torch.tensors`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YzPb-nXTbvV"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# training parameters\n",
    "hidden_layers = [1, 20, 20, 20, 1]\n",
    "learning_rate = 0.001\n",
    "training_iter = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUUlUvTETbvV"
   },
   "outputs": [],
   "source": [
    "# Define a loss function (Mean Squared Error) for training the network\n",
    "MSE_func = nn.MSELoss()\n",
    "\n",
    "# Convert the NumPy arrays to PyTorch tensors and add an extra dimension\n",
    "# test time Numpy array to Pytorch tensor\n",
    "t_test = torch.tensor(t_eval, device=device, requires_grad=True).view(-1,1).float()\n",
    "# train time Numpy array to Pytorch tensor\n",
    "t_data = torch.tensor(t_data, device=device, requires_grad=True).view(-1,1).float()\n",
    "# Numerical theta to test Numpy array to pytorch tensor\n",
    "theta_test = torch.tensor(theta_num, device=device, requires_grad=True).view(-1,1).float()\n",
    "# Numerical theta to train Numpy array to pytorch tensor\n",
    "theta_data = torch.tensor(theta_data, device=device, requires_grad=True).view(-1,1).float()\n",
    "\n",
    "# Define a neural network class with user defined layers and neurons\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, hlayers):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(hlayers[:-2])):\n",
    "            layers.append(nn.Linear(hlayers[i], hlayers[i+1]))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(hlayers[-2], hlayers[-1]))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        \"\"\"Xavier Glorot parameter initialization of the Neural Network\n",
    "        \"\"\"\n",
    "        def init_normal(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight) # Xavier\n",
    "        self.apply(init_normal)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1XnbAucTbvV",
    "outputId": "157c08c8-fe8f-40dc-f9c9-8d85f04d9281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 901\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the neural network\n",
    "theta_ann = NeuralNetwork(hidden_layers).to(device)\n",
    "nparams = sum(p.numel() for p in theta_ann.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {nparams}')\n",
    "\n",
    "# Define an optimizer (Adam) for training the network\n",
    "optimizer = optim.Adam(theta_ann.parameters(), lr=learning_rate,\n",
    "                       betas= (0.9,0.999), eps = 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue3HStEcTbvW"
   },
   "source": [
    "### Función de pérdida \n",
    "\n",
    "Para entrenar la ANN necesitamos datos y una función de pérdida. Nuestros datos serán observaciones ruidosas de la solución $\\theta_{data}(t)$, obtenidas en puntos de colocación $\\{t_i\\}_N$ elegidos del dominio. Utilizamos como función de pérdida el error cuadrático medio ($MSE$) entre estas observaciones y la evaluación de la ANN en los mismos puntos de colocación, es decir,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\Theta) := \\lambda_1 MSE(\\theta_{NN}(t; \\Theta), \\theta_{data}(t)) = \\frac{\\lambda_1}{N}\\sum_i (\\theta_{NN}(t_i; \\Theta) - \\theta_{data}(t_i))^2\n",
    "$$\n",
    "\n",
    "donde $\\lambda_1 \\in \\mathbb{R}^+$ es un peso positivo y $N$ es el número de muestras. El entrenamiento se realiza minimizando la función de pérdida $\\mathcal{L}(\\Theta)$, es decir,\n",
    "\n",
    "$$\n",
    "\\min_{\\Theta \\in \\mathbb{R}} \\mathcal{L}(\\Theta) \\rightarrow 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbcXCC2CTbvW",
    "outputId": "74ad7d01-3a5b-45ff-b7ef-8a30db60cad5"
   },
   "outputs": [],
   "source": [
    "def NeuralNetworkLoss(forward_pass, t, theta_data, lambda1 = 1):\n",
    "\n",
    "    theta_nn = forward_pass(t)\n",
    "    data_loss = lambda1 * MSE_func(theta_nn, theta_data)\n",
    "\n",
    "    return  data_loss\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "loss_values_ann = []\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the neural network\n",
    "for i in range(training_iter):\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "\n",
    "    # input x and predict based on x\n",
    "    loss = NeuralNetworkLoss(theta_ann,\n",
    "                             t_data,\n",
    "                             theta_data)    # must be (1. nn output, 2. target)\n",
    "\n",
    "    # Append the current loss value to the list\n",
    "    loss_values_ann.append(loss.item())\n",
    "\n",
    "    if i % 1000 == 0:  # print every 100 iterations\n",
    "        print(f\"Iteration {i}: Loss {loss.item()}\")\n",
    "\n",
    "    loss.backward() # compute gradients (backpropagation)\n",
    "    optimizer.step() # update the ANN weigths\n",
    "\n",
    "# Stop the timer and calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training time: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sITbWTKXTbvW"
   },
   "source": [
    "graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "53BRPDdjTbvX",
    "outputId": "febce2b5-b3bf-418d-8cf5-d9129a792ede"
   },
   "outputs": [],
   "source": [
    "theta_pred_ann = theta_ann(t_test).to(device)\n",
    "\n",
    "print(f'Relative error: {relative_l2_error(theta_pred_ann, theta_test)}')\n",
    "\n",
    "plot_comparison(t_test, theta_num, theta_pred_ann, loss_values_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bE2S96IyTbvX"
   },
   "source": [
    "## 4. Entrenando la Red Neuronal Informada por Física (PINN)\n",
    "\n",
    "Ahora queremos entrenar una PINN de para aproximar la solución de la EDO,\n",
    "\n",
    "$$\n",
    "\\theta_{PINN}(t; \\Theta) \\approx \\theta(t).\n",
    "$$\n",
    "\n",
    "Esta PINN tendrá la misma arquitectura que la ANN que usamos anteriormente, pero esta vez la entrenaremos incorporando la física del problema además de las observaciones. Usaremos las mismas observaciones ruidosas (**datos de entrenamiento**) que antes, pero también incluiremos las ecuaciones que describen el comportamiento de las derivadas de la solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7_P7E9vTbvX",
    "outputId": "72567b58-3028-4dca-c961-95ce3a1519c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 901\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the neural network\n",
    "theta_pinn = NeuralNetwork(hidden_layers).to(device)\n",
    "nparams = sum(p.numel() for p in theta_pinn.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {nparams}')\n",
    "\n",
    "# Define an optimizer (Adam) for training the network\n",
    "optimizer = optim.Adam(theta_pinn.parameters(), lr=learning_rate,\n",
    "                       betas= (0.9,0.999), eps = 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferenciación automática en PyTorch \n",
    "\n",
    "Antes de continuar será útil aprender a calcular las derivadas de una red neuronal. Para esto utilizaremos la diferenciación automática (*autodiff*), que es una técnica para calcular gradientes de funciones de forma eficiente y precisa mediante el uso de la regla de la cadena. PyTorch registra la forma en que operamos las variables en un gráfico computacional dinámico, que luego le permite calcular derivadas automáticamente al realizar una \"propagación hacia atrás\" (*backpropagation*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir tensor de entrada. Si queremos derivar c/r a x necesitamos inicializar con requires_grad=True\n",
    "x = torch.tensor([1.0, 2.0, 3.0], device=device, requires_grad=True).view(-1,1).float() # (N,1)\n",
    "\n",
    "# Calcular operación que dependen de x\n",
    "y = x**2 # (N,1)  \n",
    "\n",
    "# Calcular derivadas c/r a x \n",
    "# grad es un wrapper de torch.autograd\n",
    "dy_dx = grad(y, x) \n",
    "\n",
    "# Calcular derivadas de orden superior\n",
    "d2y_dx2 = grad(dy_dx, x)  \n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"y = x^2:\", y)\n",
    "print(\"dy/dx:\", dy_dx)\n",
    "print(\"d^2y/dx^2:\", d2y_dx2)  \n",
    "\n",
    "# Esto también funciona para redes neuronales\n",
    "NNx = theta_pinn(x)\n",
    "dNNx_dx = grad(NNx, x)\n",
    "print(\"NNx: \", dNNx_dx)\n",
    "print(\"dNNx/dx:\", dNNx_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wS25mOJTbvX"
   },
   "source": [
    "### Función de pérdida informada por la física del problema\n",
    "\n",
    "Para entrenar la PINN, recordemos el modelo del péndulo y definamos las funciones $f_{ode}(t;g,l)$, $g_{ic}(0)$ y $h_{bc}(0)$ para la ODE, la condición inicial y la condición de frontera. Además, reemplazamos la solución analítica $\\theta(t)$ con la salida de la PINN $\\theta_{pinn}(t; \\Theta)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{ode}(t;\\theta_{pinn}):=&\\frac{d^2\\theta_{PINN}(t; \\Theta)}{dt^2}+\\frac{g}{l}\\sin(\\theta_{pinn}(t; \\Theta)) = 0\\\\\n",
    "g_{ic}(0;\\theta_{pinn}):=&\\theta_{pinn}(0; \\Theta) = \\theta_0\\\\\n",
    "h_{bc}(0;\\theta_{pinn}):=&\\theta_{pinn}'(0; \\Theta) = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nuevamente utilizamos el $MSE$ y definimos la función de pérdida informada por física:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta):= &\\frac{\\lambda_1}{N}\\sum_i\\left(f_{ode}(t_i;\\theta_{pinn})-0\\right)^2 \\quad \\text{Pérdida de la ODE}\\\\\n",
    "                   & + \\lambda_2 (g_{ic}(0;\\theta_{pinn})-\\theta_0)^2 \\quad \\text{Pérdida de la condición inicial IC}\\\\\n",
    "                   & + \\lambda_3 (h_{bc}(0;\\theta_{pinn})-0)^2 \\quad \\text{Pérdida de la condición de frontera BC}\\\\\n",
    "                   & + \\frac{\\lambda_4}{N}\\sum_i (\\theta_{pinn}(t_i; \\Theta) - \\theta_{data}(t_i))^2 \\quad \\text{Pérdida de los datos (DATA)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde $\\lambda_{1,2,3,4}\\in\\mathbb{R}^+$ son pesos positivos y $N$ es el número de muestras. \n",
    "\n",
    "<div class=\"alert alert-info\"\n",
    "    style=\"background-color:#5c5c5c;color:#000000;border-color:#000000\">\n",
    "  <strong>REMARK!</strong> Cuando no incluimos la función de pérdida relacionada con los datos, estamos empleando un esquema independiente de datos (*data-free*); cuando incluimos los datos, estamos empleando un esquema impulsado por datos (*data-driven*).\n",
    "</div>\n",
    "\n",
    "El entrenamiento se realiza minimizando la función de pérdida $\\mathcal{L}(\\Theta)$, es decir,\n",
    "\n",
    "$$\n",
    "\\min_{\\Theta\\in\\mathbb{R}} \\mathcal{L}(\\Theta)\\rightarrow 0\n",
    "$$\n",
    "\n",
    "<div class=\"alert alert-info\"\n",
    "    style=\"background-color:#5c5c5c;color:#000000;border-color:#000000\">\n",
    "  <strong>REMARK!</strong> La diferenciación automática (`torch.autograd`) es una herramienta poderosa para calcular los gradientes de la PINN con respecto a la entrada, lo que será útil para evaluar la función de pérdida. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlUB-YF3TbvY",
    "outputId": "223a5d0a-051e-4353-99e6-ac08220e85f3"
   },
   "outputs": [],
   "source": [
    "# Define t = 0 for boundary an initial conditions\n",
    "t0 = torch.tensor(0., device=device, requires_grad=True).view(-1,1)\n",
    "\n",
    "# HINT: use grad funtion (a wraper for torch.autograd) to calculate the\n",
    "# derivatives of the ANN\n",
    "def PINNLoss(forward_pass, t_phys, t_data, theta_data,\n",
    "             lambda1 = 1, lambda2 = 1, lambda3 = 1, lambda4 = 1):\n",
    "\n",
    "    # ANN output, first and second derivatives\n",
    "    theta_pinn1 = forward_pass(t_phys)\n",
    "    #TODO: calculate the first and second derivatives\n",
    "\n",
    "    #TODO: calculate the ODE loss\n",
    "\n",
    "    g_ic = forward_pass(t0)\n",
    "    IC_loss = lambda2 * MSE_func(g_ic, torch.ones_like(g_ic)*theta0)\n",
    "\n",
    "    #TODO: calculate boundary condition\n",
    "\n",
    "    theta_nn2 = forward_pass(t_data)\n",
    "    data_loss = lambda4 * MSE_func(theta_nn2, theta_data)\n",
    "\n",
    "    return ODE_loss + IC_loss + BC_loss + data_loss\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "loss_values_pinn = []\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the neural network\n",
    "for i in range(training_iter):\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "\n",
    "    # input x and predict based on x\n",
    "    loss = PINNLoss(theta_pinn, t_test, t_data, theta_data)\n",
    "\n",
    "    # Append the current loss value to the list\n",
    "    loss_values_pinn.append(loss.item())\n",
    "\n",
    "    if i % 1000 == 0:  # print every 100 iterations\n",
    "        print(f\"Iteration {i}: Loss {loss.item()}\")\n",
    "\n",
    "    loss.backward() # compute gradients (backpropagation)\n",
    "    optimizer.step() # update the ANN weigths\n",
    "\n",
    "# Stop the timer and calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G70N-xiTbvY"
   },
   "source": [
    "Nuevamente, graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "sLEu3EJbTbvY",
    "outputId": "391ca19f-ebdf-4b56-ea72-ab9d4512646d"
   },
   "outputs": [],
   "source": [
    "theta_pred_pinn = theta_pinn(t_test)\n",
    "\n",
    "print(f'Relative error: {relative_l2_error(theta_pred_pinn, theta_test)}')\n",
    "\n",
    "plot_comparison(t_test, theta_num, theta_pred_pinn, loss_values_pinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3DZxHeBTbvY"
   },
   "source": [
    "## 5. Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z1e1kIGaTbvZ",
    "outputId": "ac388224-0634-4895-b5f4-1aba257b94bf"
   },
   "outputs": [],
   "source": [
    "plot_comparison(t_test, theta_num, theta_pred_ann, loss_values_ann)\n",
    "plot_comparison(t_test, theta_num, theta_pred_pinn, loss_values_pinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfSHJ_0hTbvZ"
   },
   "source": [
    "## **Ejercicios**:\n",
    "\n",
    "1. Elimina la pérdida de los datos del entrenamiento de la PINN. ¿Aún se puede obtener la solución?\n",
    "2. Incrementa y reduce el parámetro `std_deviation` en la sección [Preparación de los datos de entrenamiento](#data_prep) para cambiar el `SNR`. También cambia las variables `resample` y `ctime`, y compara los resultados tras entrenar la ANN y la PINN.\n",
    "3. Ajusta los valores de los parámetros `lambdas` en la función de pérdida para ambas redes y analiza su impacto.\n",
    "4. Modifica la tasa de aprendizaje (`learning_rate`) del optimizador y el número de iteraciones de entrenamiento, y evalúa el efecto en el desempeño.\n",
    "5. Cambia el número de capas ocultas (`hidden_layers`), neuronas y funciones de activación de la red neuronal, y observa el impacto en los resultados.\n",
    "\n",
    "## **Preguntas**:\n",
    "\n",
    "1. **¿Cómo se puede abordar el sobreajuste en las PINNs si el objetivo es aprender los operadores subyacentes del sistema físico?**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   El sobreajuste en las PINNs (Physics-Informed Neural Networks) es un tema ampliamente discutido. En el aprendizaje automático tradicional, el sobreajuste se asocia con la incapacidad de un modelo para generalizar a datos no vistos previamente, lo que afecta su capacidad para realizar predicciones precisas en nuevas entradas. Sin embargo, en el contexto de las PINNs, buscamos un comportamiento diferente: que la red neuronal funcione como un modelo surrogate de la solución de las ecuaciones diferenciales que describen el sistema físico. En este caso, el sobreajuste no necesariamente es perjudicial, ya que queremos que la red reproduzca fielmente la solución dentro del dominio especificado.\n",
    "\n",
    "   El desafío relacionado con la generalización en las PINNs surge cuando estas redes se evalúan en geometrías más complejas o diferentes de las que fueron utilizadas durante el entrenamiento. En tales casos, una PINN que esté sobreajustada a una única geometría podría fallar al adaptarse a las nuevas configuraciones, comprometiendo su capacidad para generalizar y capturar las dinámicas físicas subyacentes en contextos más diversos. Por ello, abordar el sobreajuste implica equilibrar la fidelidad al dominio original y la adaptabilidad a nuevas geometrías o condiciones.\n",
    "   </details>\n",
    "\n",
    "\n",
    "2. **Qué ventajas ofrece el uso del MSE en la función de pérdida, dado que este enfoque puede subestimar la solución al no incorporar formulaciones integrales o variacionales**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   El uso del MSE como función de pérdida proporciona una forma sencilla y computacionalmente eficiente de medir las diferencias puntuales entre las predicciones del modelo y los valores objetivo. Sin embargo, el MSE se centra únicamente en puntos individuales, lo que puede limitar su capacidad para capturar el comportamiento global de la solución, especialmente en dominios complejos. Al incorporar formulaciones integrales o variacionales, la función de pérdida puede reflejar el comportamiento de la solución en todo el dominio, mejorando potencialmente la precisión y estabilidad. A pesar de estas limitaciones, el MSE sigue siendo popular porque simplifica la implementación y reduce los costos computacionales, lo que lo hace adecuado para muchas aplicaciones prácticas.\n",
    "   </details>\n",
    "\n",
    "\n",
    "3. **¿En qué formas son ventajosas las PINNs comparadas con los métodos numéricos tradicionales, considerando el mayor tiempo requerido para el entrenamiento?**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   Las PINNs ofrecen varias ventajas frente a los métodos numéricos tradicionales, a pesar de su tiempo de entrenamiento generalmente más largo. Una ventaja clave es su flexibilidad para manejar dominios complejos, de alta dimensionalidad y geometrías irregulares sin requerir mallas estructuradas. Las PINNs también pueden incorporar fácilmente restricciones o datos adicionales, como mediciones experimentales o condiciones de frontera. A diferencia de muchos métodos numéricos, una vez entrenadas, las PINNs generalizan bien a diferentes condiciones iniciales y de frontera, lo que puede hacerlas más versátiles en escenarios que requieren simulaciones repetidas o ajustes de parámetros. Esta flexibilidad y adaptabilidad las convierten en una herramienta poderosa para ciertas tareas de modelado informadas por física donde los métodos tradicionales pueden estar limitados.\n",
    "   </details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HohsYU0hTbvZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pinns-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
